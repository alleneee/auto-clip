#!/usr/bin/env python3
"""
å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹æµ‹è¯•
ä»è§†é¢‘åˆ†æã€å‰ªè¾‘å†³ç­–ã€è„šæœ¬ç”Ÿæˆã€TTSã€åˆ°æœ€ç»ˆè§†é¢‘ç”Ÿæˆ
"""
import os
import sys
import asyncio
import json
from pathlib import Path
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ° Python è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

from app.adapters.vision_adapters import DashScopeVisionAdapter
from app.adapters.audio_adapters import ParaformerSpeechAdapter
from app.prompts.llm_prompts import VideoAnalysisPrompts, ClipDecisionPrompts
from app.utils.video_utils import video_to_base64, get_video_info
from app.utils.audio_utils import extract_audio_from_video
from app.utils.oss_client import oss_client
from app.services.video_compression import video_compression_service
from app.utils.ai_clients.dashscope_client import DashScopeClient
from app.services.video_production_orchestrator import video_production_orchestrator


def print_section(title: str):
    """æ‰“å°ç« èŠ‚æ ‡é¢˜"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80)


def clean_json_response(response: str) -> str:
    """æ¸…ç†LLMè¿”å›çš„JSONï¼ˆç§»é™¤markdownä»£ç å—æ ‡è®°ï¼‰"""
    response = response.strip()
    if response.startswith("```json"):
        response = response[7:]
    elif response.startswith("```"):
        response = response[3:]
    if response.endswith("```"):
        response = response[:-3]
    return response.strip()


async def test_full_production():
    """æµ‹è¯•å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹"""
    print_section("å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹æµ‹è¯• - ä»åˆ†æåˆ°æˆå“è§†é¢‘")

    test_video = "tmp/7514135682735639860.mp4"
    compressed_video = "tmp/test_compressed_production.mp4"
    audio_path = "tmp/test_audio_production.mp3"
    audio_oss_path = "test/test_audio_production.mp3"

    # æœ€ç»ˆè¾“å‡ºè§†é¢‘
    final_video = f"tmp/final_video_{datetime.now().strftime('%Y%m%d_%H%M%S')}.mp4"

    try:
        if not os.path.exists(test_video):
            print(f"âŒ æµ‹è¯•è§†é¢‘ä¸å­˜åœ¨: {test_video}")
            return False

        print(f"\nğŸ“¹ æµ‹è¯•è§†é¢‘: {test_video}")
        video_info = get_video_info(test_video)
        print(f"   æ—¶é•¿: {video_info['duration']:.2f}ç§’")
        print(f"   åˆ†è¾¨ç‡: {video_info['width']}x{video_info['height']}")
        print(f"   å¤§å°: {video_info['size_bytes'] / 1024 / 1024:.2f} MB")

        # ==================== é˜¶æ®µ A: è§†é¢‘åˆ†æå’Œå‰ªè¾‘å†³ç­– ====================
        print_section("é˜¶æ®µ A: è§†é¢‘åˆ†æå’Œå‰ªè¾‘å†³ç­– (å¤ç”¨ä¹‹å‰çš„æµç¨‹)")

        # A1. å‹ç¼©è§†é¢‘
        print("\nğŸ—œï¸  å‹ç¼©è§†é¢‘...")
        compressed_path, stats = await video_compression_service.compress_video(
            input_path=test_video,
            output_path=compressed_video,
            profile_name="aggressive"
        )
        print(f"âœ… å‹ç¼©å®Œæˆ: {stats['original_size'] / 1024 / 1024:.2f} MB â†’ "
              f"{stats['compressed_size'] / 1024 / 1024:.2f} MB")

        # A2. è§†è§‰åˆ†æ
        print("\nğŸ¤– è°ƒç”¨ VL æ¨¡å‹è·å–è§†è§‰åˆ†æ...")
        video_base64 = video_to_base64(compressed_path)
        vision_adapter = DashScopeVisionAdapter()

        visual_result = await vision_adapter.analyze_from_base64(
            video_base64=video_base64,
            prompt=VideoAnalysisPrompts.VISUAL_ANALYSIS_JSON
        )

        visual_json_text = clean_json_response(visual_result)
        visual_json = json.loads(visual_json_text)
        print(f"âœ… VL åˆ†æå®Œæˆ: {len(visual_json.get('segments', []))} ä¸ªæ—¶é—´åˆ†æ®µ")

        # A3. è¯­éŸ³è¯†åˆ«
        print("\nğŸµ æå–éŸ³é¢‘å¹¶è¿›è¡ŒASRè¯†åˆ«...")
        extract_audio_from_video(test_video, audio_path)
        await oss_client.upload(local_path=audio_path, oss_path=audio_oss_path)
        audio_url = oss_client.generate_signed_url(audio_oss_path, expires=86400)

        speech_adapter = ParaformerSpeechAdapter()
        asr_transcription = await speech_adapter.transcribe_from_url(
            audio_url=audio_url,
            language_hints=["zh", "en"]
        )
        print(f"âœ… ASR è¯†åˆ«å®Œæˆ: {len(asr_transcription.get('sentences', []))} å¥è¯")

        # A4. ç”Ÿæˆå‰ªè¾‘å†³ç­–
        print("\nğŸ“ ç”Ÿæˆå‰ªè¾‘å†³ç­–...")
        video_analyses = [
            {
                'video_id': 'video_001',
                'duration': video_info['duration'],
                'visual_analysis_json': visual_json,
                'asr_transcription': asr_transcription
            }
        ]

        enhanced_prompt = ClipDecisionPrompts.generate_enhanced_clip_decision_prompt(
            theme="è¿åŠ¨é‹äº§å“å±•ç¤ºç²¾å½©ç‰‡æ®µ",
            video_analyses=video_analyses,
            target_duration=10
        )

        llm_client = DashScopeClient()
        clip_decision_response = await llm_client.chat(
            prompt=enhanced_prompt,
            system_prompt=ClipDecisionPrompts.CLIP_DECISION_SYSTEM
        )

        clip_decision_text = clean_json_response(clip_decision_response)
        clip_decision = json.loads(clip_decision_text)

        print(f"âœ… å‰ªè¾‘å†³ç­–ç”Ÿæˆå®Œæˆ:")
        print(f"   - ä¸»é¢˜: {clip_decision.get('theme', '')}")
        print(f"   - ç‰‡æ®µæ•°: {len(clip_decision.get('clips', []))}")
        print(f"   - ç›®æ ‡æ—¶é•¿: {clip_decision.get('total_duration', 0)}ç§’")

        # ä¿å­˜å‰ªè¾‘å†³ç­–
        decision_file = "tmp/clip_decision_for_production.json"
        with open(decision_file, 'w', encoding='utf-8') as f:
            json.dump(clip_decision, f, ensure_ascii=False, indent=2)
        print(f"ğŸ’¾ å‰ªè¾‘å†³ç­–å·²ä¿å­˜: {decision_file}")

        # ==================== é˜¶æ®µ B: å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹ ====================
        print_section("é˜¶æ®µ B: å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹ (æ–°æµç¨‹)")

        print("\nğŸ¬ å¼€å§‹è°ƒç”¨ VideoProductionOrchestrator...")
        print(f"   é…éŸ³é£æ ¼: professional")
        print(f"   TTSéŸ³è‰²: Cherry (å¥³å£°)")
        print(f"   æ˜¯å¦æ·»åŠ é…éŸ³: True")
        print(f"   åŸéŸ³éŸ³é‡: 0.2 (é™ä½åŸéŸ³ï¼Œçªå‡ºé…éŸ³)")

        # è°ƒç”¨ç¼–æ’æœåŠ¡ç”Ÿæˆæœ€ç»ˆè§†é¢‘
        production_result = await video_production_orchestrator.produce_video_from_decision(
            source_videos=[test_video],
            clip_decision=clip_decision,
            output_path=final_video,
            narration_style="professional",
            narration_voice="Cherry",  # ä½¿ç”¨qwen3-tts-flashæ”¯æŒçš„CherryéŸ³è‰²
            add_narration=True,
            background_music_path=None,  # æš‚ä¸æ·»åŠ èƒŒæ™¯éŸ³ä¹
            original_audio_volume=0.2  # é™ä½åŸéŸ³ï¼Œè®©é…éŸ³æ›´æ¸…æ™°
        )

        # ==================== æµ‹è¯•ç»“æœæ€»ç»“ ====================
        print_section("æµ‹è¯•ç»“æœæ€»ç»“")

        print("\nâœ… å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹æµ‹è¯•é€šè¿‡!")

        print(f"\nğŸ“Š æµç¨‹ç»Ÿè®¡:")
        print(f"   ã€é˜¶æ®µA - è§†é¢‘åˆ†æã€‘")
        print(f"   - åŸå§‹è§†é¢‘: {video_info['size_bytes'] / 1024 / 1024:.2f} MB")
        print(f"   - å‹ç¼©å: {stats['compressed_size'] / 1024 / 1024:.2f} MB")
        print(f"   - è§†è§‰åˆ†æ®µ: {len(visual_json.get('segments', []))} ä¸ª")
        print(f"   - è¯­éŸ³å¥å­: {len(asr_transcription.get('sentences', []))} å¥")
        print(f"   - å‰ªè¾‘ç‰‡æ®µ: {len(clip_decision.get('clips', []))} ä¸ª")

        print(f"\n   ã€é˜¶æ®µB - è§†é¢‘ç”Ÿæˆã€‘")
        stats = production_result['statistics']
        print(f"   - æœ€ç»ˆè§†é¢‘æ—¶é•¿: {stats['final_duration']:.2f}ç§’")
        print(f"   - æœ€ç»ˆæ–‡ä»¶å¤§å°: {stats['final_size_mb']:.2f}MB")
        print(f"   - æ€»å¤„ç†æ—¶é—´: {stats['processing_time']:.2f}ç§’")
        print(f"   - é…éŸ³çŠ¶æ€: {'å·²æ·»åŠ ' if stats['has_narration'] else 'æœªæ·»åŠ '}")
        if stats.get('script_word_count'):
            print(f"   - è„šæœ¬å­—æ•°: {stats['script_word_count']}å­—")
            print(f"   - é¢„ä¼°æœ—è¯»æ—¶é•¿: {stats['script_estimated_duration']:.1f}ç§’")

        print(f"\nğŸ“ è¾“å‡ºæ–‡ä»¶:")
        print(f"   - å‰ªè¾‘å†³ç­–: {decision_file}")
        print(f"   - æœ€ç»ˆè§†é¢‘: {production_result['final_video_path']}")
        print(f"   - ä¸­é—´æ–‡ä»¶æ•°é‡: {len(production_result['intermediate_files'])}")

        # å¯é€‰: æ˜¾ç¤ºä¸­é—´æ–‡ä»¶åˆ—è¡¨
        print(f"\nğŸ“‚ ä¸­é—´æ–‡ä»¶åˆ—è¡¨:")
        for i, file_path in enumerate(production_result['intermediate_files'], 1):
            file_size = os.path.getsize(file_path) / 1024
            print(f"   {i}. {Path(file_path).name} ({file_size:.2f}KB)")

        # ==================== æ¸…ç†ä¸´æ—¶æ–‡ä»¶ ====================
        print_section("æ¸…ç†ä¸´æ—¶æ–‡ä»¶")

        print("\nğŸ—‘ï¸  æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
        if os.path.exists(compressed_video):
            os.remove(compressed_video)
            print(f"âœ… åˆ é™¤: {compressed_video}")
        if os.path.exists(audio_path):
            os.remove(audio_path)
            print(f"âœ… åˆ é™¤: {audio_path}")
        await oss_client.delete(audio_oss_path)
        print(f"âœ… åˆ é™¤: OSS/{audio_oss_path}")

        # æ³¨æ„: ä¿ç•™æœ€ç»ˆè§†é¢‘å’Œä¸­é—´æ–‡ä»¶ç”¨äºæ£€æŸ¥
        print(f"\nğŸ’¡ æç¤º: æœ€ç»ˆè§†é¢‘å’Œä¸­é—´æ–‡ä»¶å·²ä¿ç•™ï¼Œå¯æ‰‹åŠ¨æŸ¥çœ‹éªŒè¯")

        return True

    except Exception as e:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥: {str(e)}")
        import traceback
        traceback.print_exc()

        # æ¸…ç†å¯èƒ½æ®‹ç•™çš„æ–‡ä»¶
        try:
            if os.path.exists(compressed_video):
                os.remove(compressed_video)
            if os.path.exists(audio_path):
                os.remove(audio_path)
            if oss_client.object_exists(audio_oss_path):
                await oss_client.delete(audio_oss_path)
        except:
            pass

        return False


async def main():
    """ä¸»å‡½æ•°"""
    print("\n" + "ğŸ¬" * 40)
    print("  å®Œæ•´è§†é¢‘ç”Ÿæˆæµç¨‹æµ‹è¯•")
    print("  è§†é¢‘åˆ†æ â†’ å‰ªè¾‘å†³ç­– â†’ è„šæœ¬ç”Ÿæˆ â†’ TTS â†’ æœ€ç»ˆè§†é¢‘")
    print("ğŸ¬" * 40)

    success = await test_full_production()

    if success:
        print("\nğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼å®Œæ•´è§†é¢‘ç”Ÿæˆç³»ç»Ÿå·¥ä½œæ­£å¸¸ï¼")
    else:
        print("\nâš ï¸  æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥é”™è¯¯ä¿¡æ¯")

    print("\n" + "ğŸ¬" * 40)


if __name__ == "__main__":
    asyncio.run(main())
